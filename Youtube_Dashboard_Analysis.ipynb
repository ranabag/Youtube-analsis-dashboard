{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtivX2zkFazGXPD3Jbw5ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranabag/Youtube-analsis-dashboard/blob/main/Youtube_Dashboard_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('C:/Users/HP/Downloads/archive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "5Y8YGOUe-aW8",
        "outputId": "2abee0d4-154f-4093-9428-427b2f5d7a6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must be in a directory that exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2668093749.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Users/HP/Downloads/archive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must be in a directory that exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGKILL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must be in a directory that exists"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M01OXxhUV5kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import datetime\n",
        "import wordcloud\n",
        "import json\n",
        "\n",
        "# --- Configuration ---\n",
        "# Read the data and set configuration options\n",
        "try:\n",
        "    df = pd.read_csv(\"USvideos.csv\", engine='python') # Added engine='python'\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'USvideos.csv' not found. Make sure the file is in the correct directory.\")\n",
        "    # Exit or create a dummy dataframe to allow the rest of the script to run without error\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "PLOT_COLORS = [\"#268bd2\", \"#0052CC\", \"#FF5722\", \"#b58900\", \"#003f5c\"]\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "sns.set(style=\"ticks\")\n",
        "plt.rc('figure', figsize=(8, 5), dpi=100)\n",
        "plt.rc('axes', labelpad=20, facecolor=\"#ffffff\", linewidth=0.4, grid=True, labelsize=14)\n",
        "plt.rc('patch', linewidth=0)\n",
        "plt.rc('xtick.major', width=0.2)\n",
        "plt.rc('ytick.major', width=0.2)\n",
        "plt.rc('grid', color='#9E9E9E', linewidth=0.4)\n",
        "plt.rc('font', family='Arial', weight='400', size=10)\n",
        "plt.rc('text', color='#282828')\n",
        "plt.rc('savefig', pad_inches=0.3, dpi=300)\n",
        "\n",
        "# --- Data Exploration ---\n",
        "# Fill missing description values\n",
        "if 'description' in df.columns:\n",
        "    df[\"description\"] = df[\"description\"].fillna(value=\"\")\n",
        "# The df.describe() line is meant for interactive exploration, so it's often omitted in a final script\n",
        "\n",
        "# --- Data Visualization ---\n",
        "\n",
        "# Check if dataframe is empty before attempting to plot\n",
        "if not df.empty:\n",
        "    # FIX 1: Corrected the function's logic\n",
        "    def contains_capitalized_word(s):\n",
        "        # The function now checks all words before returning False\n",
        "        for w in s.split():\n",
        "            if w.isupper():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # Pie Chart: Title Contains Capitalized Word?\n",
        "    if 'title' in df.columns:\n",
        "        df[\"contains_capitalized\"] = df[\"title\"].apply(contains_capitalized_word)\n",
        "        value_counts = df[\"contains_capitalized\"].value_counts()\n",
        "\n",
        "        # FIX 2: Made pie chart data access safer\n",
        "        false_count = value_counts.get(False, 0)\n",
        "        true_count = value_counts.get(True, 0)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.pie([false_count, true_count], labels=['No', 'Yes'],\n",
        "               colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'}, startangle=45)\n",
        "        ax.axis('equal')\n",
        "        ax.set_title('Title Contains Capitalized Word?')\n",
        "\n",
        "    # Histogram: Title Length\n",
        "    if 'title' in df.columns:\n",
        "        df[\"title_length\"] = df[\"title\"].apply(lambda x: len(x))\n",
        "        fig, ax = plt.subplots()\n",
        "\n",
        "        # FIX 3: Replaced deprecated 'distplot' with 'histplot'\n",
        "        sns.histplot(data=df, x=\"title_length\", kde=False,\n",
        "                     color=PLOT_COLORS[4], ax=ax)\n",
        "\n",
        "        ax.set(xlabel=\"Title Length\", ylabel=\"No. of videos\", xticks=range(0, 110, 10))\n",
        "\n",
        "    # Scatter Plot: Views vs. Title Length\n",
        "    if 'views' in df.columns and 'title_length' in df.columns:\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.scatter(x=df['views'], y=df['title_length'], color=PLOT_COLORS[2],\n",
        "                   edgecolors=\"#000000\", linewidths=0.5)\n",
        "        ax.set(xlabel=\"Views\", ylabel=\"Title Length\")\n",
        "\n",
        "\n",
        "    # Heatmap: Correlation of Trending Video Metrics\n",
        "    # FIX 4: Made the correlation calculation and labeling more robust\n",
        "    corr_matrix = df.corr(numeric_only=True)\n",
        "    h_labels = [label.replace('_', ' ').title() for label in corr_matrix.columns]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sns.heatmap(corr_matrix, annot=True, xticklabels=h_labels, yticklabels=h_labels,\n",
        "                cmap=sns.cubehelix_palette(as_cmap=True), ax=ax)\n",
        "\n",
        "\n",
        "    # Word Cloud: Trending Words in Titles\n",
        "    if 'title' in df.columns:\n",
        "        title_words = list(df[\"title\"].apply(lambda x: x.split()))\n",
        "        title_words = [x for y in title_words for x in y]\n",
        "\n",
        "        wc = wordcloud.WordCloud(width=1200, height=500,\n",
        "                                 collocations=False, background_color=\"white\",\n",
        "                                 colormap=\"tab20b\").generate(\" \".join(title_words))\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.imshow(wc, interpolation='bilinear')\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    # Display all the plots\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"DataFrame is empty. Skipping plot generation.\")"
      ],
      "metadata": {
        "id": "A5dIyF6s_kPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoiOZZ8-7Sgz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import datetime\n",
        "import wordcloud\n",
        "import json\n",
        "\n",
        "# --- Configuration ---\n",
        "# Read the data and set configuration options\n",
        "try:\n",
        "    df = pd.read_csv(\"USvideos.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'USvideos.csv' not found. Make sure the file is in the correct directory.\")\n",
        "    # Exit or create a dummy dataframe to allow the rest of the script to run without error\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "PLOT_COLORS = [\"#268bd2\", \"#0052CC\", \"#FF5722\", \"#b58900\", \"#003f5c\"]\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "sns.set(style=\"ticks\")\n",
        "plt.rc('figure', figsize=(8, 5), dpi=100)\n",
        "plt.rc('axes', labelpad=20, facecolor=\"#ffffff\", linewidth=0.4, grid=True, labelsize=14)\n",
        "plt.rc('patch', linewidth=0)\n",
        "plt.rc('xtick.major', width=0.2)\n",
        "plt.rc('ytick.major', width=0.2)\n",
        "plt.rc('grid', color='#9E9E9E', linewidth=0.4)\n",
        "# plt.rc('font', family='Arial', weight='400', size=10) # Removed specific font\n",
        "plt.rc('text', color='#282828')\n",
        "plt.rc('savefig', pad_inches=0.3, dpi=300)\n",
        "\n",
        "# --- Data Exploration ---\n",
        "# Fill missing description values\n",
        "if 'description' in df.columns:\n",
        "    df[\"description\"] = df[\"description\"].fillna(value=\"\")\n",
        "# The df.describe() line is meant for interactive exploration, so it's often omitted in a final script\n",
        "\n",
        "# --- Data Visualization ---\n",
        "\n",
        "# Check if dataframe is empty before attempting to plot\n",
        "if not df.empty:\n",
        "    # FIX 1: Corrected the function's logic\n",
        "    def contains_capitalized_word(s):\n",
        "        # The function now checks all words before returning False\n",
        "        for w in s.split():\n",
        "            if w.isupper():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # Pie Chart: Title Contains Capitalized Word?\n",
        "    if 'title' in df.columns:\n",
        "        df[\"contains_capitalized\"] = df[\"title\"].apply(contains_capitalized_word)\n",
        "        value_counts = df[\"contains_capitalized\"].value_counts()\n",
        "\n",
        "        # FIX 2: Made pie chart data access safer\n",
        "        false_count = value_counts.get(False, 0)\n",
        "        true_count = value_counts.get(True, 0)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.pie([false_count, true_count], labels=['No', 'Yes'],\n",
        "               colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'}, startangle=45)\n",
        "        ax.axis('equal')\n",
        "        ax.set_title('Title Contains Capitalized Word?')\n",
        "\n",
        "    # Histogram: Title Length\n",
        "    if 'title' in df.columns:\n",
        "        df[\"title_length\"] = df[\"title\"].apply(lambda x: len(x))\n",
        "        fig, ax = plt.subplots()\n",
        "\n",
        "        # FIX 3: Replaced deprecated 'distplot' with 'histplot'\n",
        "        sns.histplot(data=df, x=\"title_length\", kde=False,\n",
        "                     color=PLOT_COLORS[4], ax=ax)\n",
        "\n",
        "        ax.set(xlabel=\"Title Length\", ylabel=\"No. of videos\", xticks=range(0, 110, 10))\n",
        "\n",
        "    # Scatter Plot: Views vs. Title Length\n",
        "    if 'views' in df.columns and 'title_length' in df.columns:\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.scatter(x=df['views'], y=df['title_length'], color=PLOT_COLORS[2],\n",
        "                   edgecolors=\"#000000\", linewidths=0.5)\n",
        "        ax.set(xlabel=\"Views\", ylabel=\"Title Length\")\n",
        "\n",
        "\n",
        "    # Heatmap: Correlation of Trending Video Metrics\n",
        "    # FIX 4: Made the correlation calculation and labeling more robust\n",
        "    corr_matrix = df.corr(numeric_only=True)\n",
        "    h_labels = [label.replace('_', ' ').title() for label in corr_matrix.columns]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sns.heatmap(corr_matrix, annot=True, xticklabels=h_labels, yticklabels=h_labels,\n",
        "                cmap=sns.cubehelix_palette(as_cmap=True), ax=ax)\n",
        "\n",
        "\n",
        "    # Word Cloud: Trending Words in Titles\n",
        "    if 'title' in df.columns:\n",
        "        title_words = list(df[\"title\"].apply(lambda x: x.split()))\n",
        "        title_words = [x for y in title_words for x in y]\n",
        "\n",
        "        wc = wordcloud.WordCloud(width=1200, height=500,\n",
        "                                 collocations=False, background_color=\"white\",\n",
        "                                 colormap=\"tab20b\").generate(\" \".join(title_words))\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.imshow(wc, interpolation='bilinear')\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    # Display all the plots\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"DataFrame is empty. Skipping plot generation.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"USvideos.csv\", engine='python')"
      ],
      "metadata": {
        "id": "fq0QDhOMBYzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"USvideos.csv\", engine='python', on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "McflYcP7BtZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "lM9ALcDNB74C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "CE-2sDOnCBuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import datetime\n",
        "import wordcloud\n",
        "import json\n",
        "\n",
        "# --- Configuration ---\n",
        "# Read the data and set configuration options\n",
        "try:\n",
        "    df = pd.read_csv(\"USvideos.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'USvideos.csv' not found. Make sure the file is in the correct directory.\")\n",
        "    # Exit or create a dummy dataframe to allow the rest of the script to run without error\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "PLOT_COLORS = [\"#268bd2\", \"#0052CC\", \"#FF5722\", \"#b58900\", \"#003f5c\"]\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "sns.set(style=\"ticks\")\n",
        "plt.rc('figure', figsize=(8, 5), dpi=100)\n",
        "plt.rc('axes', labelpad=20, facecolor=\"#ffffff\", linewidth=0.4, grid=True, labelsize=14)\n",
        "plt.rc('patch', linewidth=0)\n",
        "plt.rc('xtick.major', width=0.2)\n",
        "plt.rc('ytick.major', width=0.2)\n",
        "plt.rc('grid', color='#9E9E9E', linewidth=0.4)\n",
        "plt.rc('font', family='Arial', weight='400', size=10)\n",
        "plt.rc('text', color='#282828')\n",
        "plt.rc('savefig', pad_inches=0.3, dpi=300)\n",
        "\n",
        "# --- Data Exploration ---\n",
        "# Fill missing description values\n",
        "if 'description' in df.columns:\n",
        "    df[\"description\"] = df[\"description\"].fillna(value=\"\")\n",
        "# The df.describe() line is meant for interactive exploration, so it's often omitted in a final script\n",
        "\n",
        "# --- Data Visualization ---\n",
        "\n",
        "# FIX 1: Corrected the function's logic\n",
        "def contains_capitalized_word(s):\n",
        "    # The function now checks all words before returning False\n",
        "    for w in s.split():\n",
        "        if w.isupper():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Pie Chart: Title Contains Capitalized Word?\n",
        "if 'title' in df.columns:\n",
        "    df[\"contains_capitalized\"] = df[\"title\"].apply(contains_capitalized_word)\n",
        "    value_counts = df[\"contains_capitalized\"].value_counts()\n",
        "\n",
        "    # FIX 2: Made pie chart data access safer\n",
        "    false_count = value_counts.get(False, 0)\n",
        "    true_count = value_counts.get(True, 0)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie([false_count, true_count], labels=['No', 'Yes'],\n",
        "           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'}, startangle=45)\n",
        "    ax.axis('equal')\n",
        "    ax.set_title('Title Contains Capitalized Word?')\n",
        "\n",
        "# Histogram: Title Length\n",
        "if 'title' in df.columns:\n",
        "    df[\"title_length\"] = df[\"title\"].apply(lambda x: len(x))\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # FIX 3: Replaced deprecated 'distplot' with 'histplot'\n",
        "    sns.histplot(data=df, x=\"title_length\", kde=False,\n",
        "                 color=PLOT_COLORS[4], ax=ax)\n",
        "\n",
        "    ax.set(xlabel=\"Title Length\", ylabel=\"No. of videos\", xticks=range(0, 110, 10))\n",
        "\n",
        "# Scatter Plot: Views vs. Title Length\n",
        "if 'views' in df.columns and 'title_length' in df.columns:\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(x=df['views'], y=df['title_length'], color=PLOT_COLORS[2],\n",
        "               edgecolors=\"#000000\", linewidths=0.5)\n",
        "    ax.set(xlabel=\"Views\", ylabel=\"Title Length\")\n",
        "\n",
        "\n",
        "# Heatmap: Correlation of Trending Video Metrics\n",
        "# FIX 4: Made the correlation calculation and labeling more robust\n",
        "corr_matrix = df.corr(numeric_only=True)\n",
        "h_labels = [label.replace('_', ' ').title() for label in corr_matrix.columns]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, xticklabels=h_labels, yticklabels=h_labels,\n",
        "            cmap=sns.cubehelix_palette(as_cmap=True), ax=ax)\n",
        "\n",
        "\n",
        "# Word Cloud: Trending Words in Titles\n",
        "if 'title' in df.columns:\n",
        "    title_words = list(df[\"title\"].apply(lambda x: x.split()))\n",
        "    title_words = [x for y in title_words for x in y]\n",
        "\n",
        "    wc = wordcloud.WordCloud(width=1200, height=500,\n",
        "                             collocations=False, background_color=\"white\",\n",
        "                             colormap=\"tab20b\").generate(\" \".join(title_words))\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Display all the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MIfPQJGUCH68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"USvideos.csv\", engine='python', on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "sGssa_naChJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import datetime\n",
        "import wordcloud\n",
        "import json\n",
        "\n",
        "# --- Configuration ---\n",
        "# Read the data and set configuration options\n",
        "try:\n",
        "    df = pd.read_csv(\"USvideos.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'USvideos.csv' not found. Make sure the file is in the correct directory.\")\n",
        "    # Exit or create a dummy dataframe to allow the rest of the script to run without error\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "PLOT_COLORS = [\"#268bd2\", \"#0052CC\", \"#FF5722\", \"#b58900\", \"#003f5c\"]\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "sns.set(style=\"ticks\")\n",
        "plt.rc('figure', figsize=(8, 5), dpi=100)\n",
        "plt.rc('axes', labelpad=20, facecolor=\"#ffffff\", linewidth=0.4, grid=True, labelsize=14)\n",
        "plt.rc('patch', linewidth=0)\n",
        "plt.rc('xtick.major', width=0.2)\n",
        "plt.rc('ytick.major', width=0.2)\n",
        "plt.rc('grid', color='#9E9E9E', linewidth=0.4)\n",
        "plt.rc('font', family='Arial', weight='400', size=10)\n",
        "plt.rc('text', color='#282828')\n",
        "plt.rc('savefig', pad_inches=0.3, dpi=300)\n",
        "\n",
        "# --- Data Exploration ---\n",
        "# Fill missing description values\n",
        "if 'description' in df.columns:\n",
        "    df[\"description\"] = df[\"description\"].fillna(value=\"\")\n",
        "# The df.describe() line is meant for interactive exploration, so it's often omitted in a final script\n",
        "\n",
        "# --- Data Visualization ---\n",
        "\n",
        "# FIX 1: Corrected the function's logic\n",
        "def contains_capitalized_word(s):\n",
        "    # The function now checks all words before returning False\n",
        "    for w in s.split():\n",
        "        if w.isupper():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Pie Chart: Title Contains Capitalized Word?\n",
        "if 'title' in df.columns:\n",
        "    df[\"contains_capitalized\"] = df[\"title\"].apply(contains_capitalized_word)\n",
        "    value_counts = df[\"contains_capitalized\"].value_counts()\n",
        "\n",
        "    # FIX 2: Made pie chart data access safer\n",
        "    false_count = value_counts.get(False, 0)\n",
        "    true_count = value_counts.get(True, 0)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie([false_count, true_count], labels=['No', 'Yes'],\n",
        "           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'}, startangle=45)\n",
        "    ax.axis('equal')\n",
        "    ax.set_title('Title Contains Capitalized Word?')\n",
        "\n",
        "# Histogram: Title Length\n",
        "if 'title' in df.columns:\n",
        "    df[\"title_length\"] = df[\"title\"].apply(lambda x: len(x))\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # FIX 3: Replaced deprecated 'distplot' with 'histplot'\n",
        "    sns.histplot(data=df, x=\"title_length\", kde=False,\n",
        "                 color=PLOT_COLORS[4], ax=ax)\n",
        "\n",
        "    ax.set(xlabel=\"Title Length\", ylabel=\"No. of videos\", xticks=range(0, 110, 10))\n",
        "\n",
        "# Scatter Plot: Views vs. Title Length\n",
        "if 'views' in df.columns and 'title_length' in df.columns:\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(x=df['views'], y=df['title_length'], color=PLOT_COLORS[2],\n",
        "               edgecolors=\"#000000\", linewidths=0.5)\n",
        "    ax.set(xlabel=\"Views\", ylabel=\"Title Length\")\n",
        "\n",
        "\n",
        "# Heatmap: Correlation of Trending Video Metrics\n",
        "# FIX 4: Made the correlation calculation and labeling more robust\n",
        "corr_matrix = df.corr(numeric_only=True)\n",
        "h_labels = [label.replace('_', ' ').title() for label in corr_matrix.columns]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, xticklabels=h_labels, yticklabels=h_labels,\n",
        "            cmap=sns.cubehelix_palette(as_cmap=True), ax=ax)\n",
        "\n",
        "\n",
        "# Word Cloud: Trending Words in Titles\n",
        "if 'title' in df.columns:\n",
        "    title_words = list(df[\"title\"].apply(lambda x: x.split()))\n",
        "    title_words = [x for y in title_words for x in y]\n",
        "\n",
        "    wc = wordcloud.WordCloud(width=1200, height=500,\n",
        "                             collocations=False, background_color=\"white\",\n",
        "                             colormap=\"tab20b\").generate(\" \".join(title_words))\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Display all the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EFmbQzmAClzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import datetime\n",
        "from wordcloud import WordCloud\n",
        "import json\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Configuration ---\n",
        "# Read the data and set configuration options\n",
        "try:\n",
        "    df = pd.read_csv(\"USvideos.csv\")\n",
        "    print(f\"Successfully loaded data with {len(df)} rows and {len(df.columns)} columns\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'USvideos.csv' not found. Creating sample data for demonstration.\")\n",
        "    # Create sample data for testing\n",
        "    np.random.seed(42)\n",
        "    df = pd.DataFrame({\n",
        "        'title': [\n",
        "            'AMAZING YouTube Video Goes VIRAL!',\n",
        "            'how to code python tutorial',\n",
        "            'BREAKING NEWS: Something Happened',\n",
        "            'funny cat video compilation',\n",
        "            'TOP 10 Things You Need to Know',\n",
        "            'music video new release 2024',\n",
        "            'SHOCKING Results From This Experiment',\n",
        "            'daily vlog episode 100'\n",
        "        ] * 1000,\n",
        "        'views': np.random.randint(1000, 10000000, 8000),\n",
        "        'likes': np.random.randint(10, 100000, 8000),\n",
        "        'dislikes': np.random.randint(0, 5000, 8000),\n",
        "        'comment_count': np.random.randint(0, 10000, 8000),\n",
        "        'description': ['Sample description'] * 7500 + [None] * 500\n",
        "    })\n",
        "\n",
        "PLOT_COLORS = [\"#268bd2\", \"#0052CC\", \"#FF5722\", \"#b58900\", \"#003f5c\"]\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams.update({\n",
        "    'figure.figsize': (10, 6),\n",
        "    'figure.dpi': 100,\n",
        "    'axes.labelpad': 20,\n",
        "    'axes.facecolor': '#ffffff',\n",
        "    'axes.linewidth': 0.4,\n",
        "    'axes.grid': True,\n",
        "    'axes.labelsize': 12,\n",
        "    'patch.linewidth': 0,\n",
        "    'xtick.major.width': 0.2,\n",
        "    'ytick.major.width': 0.2,\n",
        "    'grid.color': '#9E9E9E',\n",
        "    'grid.linewidth': 0.4,\n",
        "    'font.family': 'sans-serif',\n",
        "    'font.weight': '400',\n",
        "    'font.size': 10,\n",
        "    'text.color': '#282828',\n",
        "    'savefig.pad_inches': 0.3,\n",
        "    'savefig.dpi': 300\n",
        "})\n",
        "\n",
        "# --- Data Exploration ---\n",
        "print(\"Dataset Info:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Fill missing description values\n",
        "if 'description' in df.columns:\n",
        "    df[\"description\"] = df[\"description\"].fillna(\"\")\n",
        "    print(f\"\\nFilled {df['description'].isna().sum()} missing descriptions\")\n",
        "\n",
        "# --- Data Visualization ---\n",
        "\n",
        "def contains_capitalized_word(title):\n",
        "    \"\"\"Check if title contains any fully capitalized words (length > 1)\"\"\"\n",
        "    if pd.isna(title) or not isinstance(title, str):\n",
        "        return False\n",
        "\n",
        "    words = title.split()\n",
        "    for word in words:\n",
        "        # Check if word is all caps and longer than 1 character\n",
        "        if len(word) > 1 and word.isupper() and word.isalpha():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# 1. Pie Chart: Title Contains Capitalized Word?\n",
        "if 'title' in df.columns:\n",
        "    print(\"\\n1. Creating pie chart for capitalized words...\")\n",
        "    df[\"contains_capitalized\"] = df[\"title\"].apply(contains_capitalized_word)\n",
        "    value_counts = df[\"contains_capitalized\"].value_counts()\n",
        "\n",
        "    false_count = value_counts.get(False, 0)\n",
        "    true_count = value_counts.get(True, 0)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    colors = ['#ff9999', '#66b3ff']\n",
        "    wedges, texts, autotexts = ax.pie(\n",
        "        [false_count, true_count],\n",
        "        labels=['No Caps', 'Has Caps'],\n",
        "        colors=colors,\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=45,\n",
        "        textprops={'fontsize': 12}\n",
        "    )\n",
        "    ax.set_title('Titles with Fully Capitalized Words', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 2. Histogram: Title Length Distribution\n",
        "if 'title' in df.columns:\n",
        "    print(\"\\n2. Creating title length histogram...\")\n",
        "    df[\"title_length\"] = df[\"title\"].str.len().fillna(0)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sns.histplot(\n",
        "        data=df,\n",
        "        x=\"title_length\",\n",
        "        bins=30,\n",
        "        kde=True,\n",
        "        color=PLOT_COLORS[4],\n",
        "        ax=ax,\n",
        "        alpha=0.7\n",
        "    )\n",
        "    ax.set_xlabel(\"Title Length (characters)\", fontsize=12)\n",
        "    ax.set_ylabel(\"Number of Videos\", fontsize=12)\n",
        "    ax.set_title(\"Distribution of Video Title Lengths\", fontsize=14, fontweight='bold')\n",
        "\n",
        "    # Add statistics\n",
        "    mean_length = df[\"title_length\"].mean()\n",
        "    median_length = df[\"title_length\"].median()\n",
        "    ax.axvline(mean_length, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_length:.1f}')\n",
        "    ax.axvline(median_length, color='orange', linestyle='--', alpha=0.7, label=f'Median: {median_length:.1f}')\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 3. Scatter Plot: Views vs. Title Length\n",
        "if 'views' in df.columns and 'title_length' in df.columns:\n",
        "    print(\"\\n3. Creating scatter plot: Views vs Title Length...\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Sample data if too large for better visualization\n",
        "    plot_df = df.sample(n=min(5000, len(df)), random_state=42)\n",
        "\n",
        "    scatter = ax.scatter(\n",
        "        x=plot_df['views'],\n",
        "        y=plot_df['title_length'],\n",
        "        color=PLOT_COLORS[2],\n",
        "        alpha=0.6,\n",
        "        edgecolors=\"white\",\n",
        "        linewidths=0.5,\n",
        "        s=30\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel(\"Views\", fontsize=12)\n",
        "    ax.set_ylabel(\"Title Length (characters)\", fontsize=12)\n",
        "    ax.set_title(\"Video Views vs Title Length\", fontsize=14, fontweight='bold')\n",
        "\n",
        "    # Add trend line\n",
        "    z = np.polyfit(plot_df['views'], plot_df['title_length'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot(plot_df['views'], p(plot_df['views']), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "    # Format x-axis for better readability\n",
        "    ax.ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 4. Correlation Heatmap\n",
        "print(\"\\n4. Creating correlation heatmap...\")\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_columns) > 1:\n",
        "    corr_matrix = df[numeric_columns].corr()\n",
        "\n",
        "    # Create better labels\n",
        "    h_labels = [col.replace('_', ' ').title() for col in corr_matrix.columns]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Show only lower triangle\n",
        "\n",
        "    sns.heatmap(\n",
        "        corr_matrix,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        mask=mask,\n",
        "        xticklabels=h_labels,\n",
        "        yticklabels=h_labels,\n",
        "        cmap='coolwarm',\n",
        "        center=0,\n",
        "        square=True,\n",
        "        ax=ax,\n",
        "        cbar_kws={\"shrink\": .8}\n",
        "    )\n",
        "    ax.set_title('Correlation Matrix of Video Metrics', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough numeric columns for correlation analysis\")\n",
        "\n",
        "# 5. Word Cloud: Trending Words in Titles\n",
        "if 'title' in df.columns:\n",
        "    print(\"\\n5. Creating word cloud...\")\n",
        "\n",
        "    # Clean and prepare text\n",
        "    all_titles = ' '.join(df['title'].dropna().astype(str))\n",
        "\n",
        "    # Remove common stop words and clean text\n",
        "    from collections import Counter\n",
        "    import re\n",
        "\n",
        "    # Basic text cleaning\n",
        "    clean_text = re.sub(r'[^\\w\\s]', ' ', all_titles.upper())\n",
        "    words = clean_text.split()\n",
        "\n",
        "    # Remove common stop words\n",
        "    stop_words = {'THE', 'AND', 'OR', 'BUT', 'IN', 'ON', 'AT', 'TO', 'FOR', 'OF', 'WITH', 'BY', 'A', 'AN'}\n",
        "    filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
        "\n",
        "    if filtered_words:\n",
        "        try:\n",
        "            wc = WordCloud(\n",
        "                width=1200,\n",
        "                height=600,\n",
        "                background_color=\"white\",\n",
        "                max_words=100,\n",
        "                colormap=\"viridis\",\n",
        "                collocations=False,\n",
        "                relative_scaling=0.5\n",
        "            ).generate(' '.join(filtered_words))\n",
        "\n",
        "            plt.figure(figsize=(15, 8))\n",
        "            plt.imshow(wc, interpolation='bilinear')\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(\"Most Common Words in Video Titles\", fontsize=16, fontweight='bold', pad=20)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Could not generate word cloud: {e}\")\n",
        "\n",
        "            # Fallback: show top words as bar chart\n",
        "            word_freq = Counter(filtered_words)\n",
        "            top_words = dict(word_freq.most_common(15))\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(12, 6))\n",
        "            bars = ax.bar(top_words.keys(), top_words.values(), color=PLOT_COLORS[0], alpha=0.8)\n",
        "            ax.set_xlabel(\"Words\", fontsize=12)\n",
        "            ax.set_ylabel(\"Frequency\", fontsize=12)\n",
        "            ax.set_title(\"Top 15 Most Common Words in Titles\", fontsize=14, fontweight='bold')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "print(\"\\nAnalysis complete! All visualizations have been generated.\")\n",
        "\n",
        "# Summary statistics\n",
        "if len(df) > 0:\n",
        "    print(f\"\\nDataset Summary:\")\n",
        "    print(f\"- Total videos analyzed: {len(df):,}\")\n",
        "    if 'views' in df.columns:\n",
        "        print(f\"- Average views: {df['views'].mean():,.0f}\")\n",
        "        print(f\"- Median views: {df['views'].median():,.0f}\")\n",
        "    if 'title_length' in df.columns:\n",
        "        print(f\"- Average title length: {df['title_length'].mean():.1f} characters\")\n",
        "    if 'contains_capitalized' in df.columns:\n",
        "        pct_caps = (df['contains_capitalized'].sum() / len(df)) * 100\n",
        "        print(f\"- Videos with capitalized words: {pct_caps:.1f}%\")"
      ],
      "metadata": {
        "id": "HFidMOeaDCkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seeds for reproducible results\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "def generate_clean_youtube_dataset(n_rows=2000):\n",
        "    \"\"\"Generate a clean, realistic YouTube trending videos dataset\"\"\"\n",
        "\n",
        "    # Realistic video title templates\n",
        "    title_templates = [\n",
        "        \"HOW TO {} IN 2024 (ACTUALLY WORKS!)\",\n",
        "        \"SHOCKING {} You Won't Believe\",\n",
        "        \"TOP 10 {} That Will BLOW Your Mind\",\n",
        "        \"BREAKING: {} Changes Everything\",\n",
        "        \"Why {} Is Taking Over\",\n",
        "        \"The TRUTH About {} Nobody Talks About\",\n",
        "        \"EPIC {} Compilation 2024\",\n",
        "        \"REACT to {} (EMOTIONAL)\",\n",
        "        \"Ultimate {} Guide for Beginners\",\n",
        "        \"{} vs {} - Which Is Better?\",\n",
        "        \"24 HOURS of {} Challenge\",\n",
        "        \"TRYING {} For The First Time\",\n",
        "        \"The {} Everyone Is Talking About\",\n",
        "        \"INSANE {} Transformation\",\n",
        "        \"Behind The Scenes: Making {}\",\n",
        "        \"Why I Quit {} After 10 Years\",\n",
        "        \"The Rise and Fall of {}\",\n",
        "        \"{} That Changed My Life\",\n",
        "        \"Ranking Every {} From WORST to BEST\",\n",
        "        \"Things About {} You Didn't Know\"\n",
        "    ]\n",
        "\n",
        "    # Content topics\n",
        "    topics = [\n",
        "        \"AI Technology\", \"Gaming Setup\", \"Cooking Recipes\", \"Fitness Workout\",\n",
        "        \"Travel Destinations\", \"Music Production\", \"Art Tutorial\", \"Science Experiment\",\n",
        "        \"Business Strategy\", \"Productivity Tips\", \"Fashion Trends\", \"Home Renovation\",\n",
        "        \"Pet Training\", \"Photography\", \"Coding Tutorial\", \"Life Hacks\", \"Movie Reviews\",\n",
        "        \"Book Recommendations\", \"Investment Advice\", \"Social Media Marketing\",\n",
        "        \"Mental Health\", \"Climate Change\", \"Space Exploration\", \"Electric Cars\",\n",
        "        \"Cryptocurrency\", \"Virtual Reality\", \"Smartphone Reviews\", \"Dating Advice\",\n",
        "        \"Career Tips\", \"Language Learning\", \"Food Reviews\", \"Travel Vlogs\"\n",
        "    ]\n",
        "\n",
        "    # Channel names\n",
        "    channels = [\n",
        "        \"TechReview Central\", \"LifeHacker Pro\", \"Creative Studio\", \"Science Explorer\",\n",
        "        \"Fitness Guru\", \"Travel Adventures\", \"Cooking Masters\", \"Gaming Zone\",\n",
        "        \"Business Insights\", \"Art Academy\", \"Music Lab\", \"Fashion Forward\",\n",
        "        \"Home Improvement\", \"Pet Paradise\", \"Photo Academy\", \"Code Academy\",\n",
        "        \"Movie Critic\", \"Book Club\", \"Finance Guru\", \"Marketing Genius\",\n",
        "        \"Wellness Guide\", \"Climate Action\", \"Space Facts\", \"Auto Review\"\n",
        "    ]\n",
        "\n",
        "    # Generate dataset\n",
        "    data = []\n",
        "    start_date = datetime(2023, 1, 1)\n",
        "\n",
        "    for i in range(n_rows):\n",
        "        # Generate realistic titles\n",
        "        template = random.choice(title_templates)\n",
        "        topic1 = random.choice(topics)\n",
        "        topic2 = random.choice(topics)\n",
        "\n",
        "        if template.count(\"{}\") == 1:\n",
        "            title = template.format(topic1)\n",
        "        else:\n",
        "            title = template.format(topic1, topic2)\n",
        "\n",
        "        # Add capitalization to some titles (realistic pattern)\n",
        "        if random.random() < 0.35:  # 35% chance\n",
        "            words = title.split()\n",
        "            caps_indices = random.sample(range(len(words)), min(random.randint(1, 3), len(words)))\n",
        "            for idx in caps_indices:\n",
        "                if len(words[idx]) > 3 and words[idx].isalpha():\n",
        "                    words[idx] = words[idx].upper()\n",
        "            title = \" \".join(words)\n",
        "\n",
        "        # Generate correlated metrics (realistic YouTube patterns)\n",
        "        # Views follow a power law distribution\n",
        "        views = max(1000, int(np.random.lognormal(mean=11.5, sigma=1.8)))\n",
        "        views = min(views, 100000000)  # Cap at 100M\n",
        "\n",
        "        # Engagement rates based on real YouTube data\n",
        "        like_rate = np.random.beta(2, 50) + 0.01  # Typically 1-8%\n",
        "        dislike_rate = like_rate * np.random.beta(1, 10)  # Much lower than likes\n",
        "        comment_rate = like_rate * np.random.beta(2, 8)  # Between likes and views\n",
        "\n",
        "        likes = max(1, int(views * like_rate))\n",
        "        dislikes = max(0, int(views * dislike_rate))\n",
        "        comment_count = max(0, int(views * comment_rate))\n",
        "\n",
        "        # Other fields\n",
        "        channel = random.choice(channels)\n",
        "        category_id = random.randint(1, 28)\n",
        "        trending_date = start_date + timedelta(days=random.randint(0, 365))\n",
        "\n",
        "        # Generate description\n",
        "        descriptions = [\n",
        "            f\"In this video, I show you everything about {topic1.lower()}. Don't forget to like and subscribe!\",\n",
        "            f\"Welcome back! Today we're diving into {topic1.lower()}. Hope you enjoy!\",\n",
        "            f\"This {topic1.lower()} guide will change everything. Links below!\",\n",
        "            f\"After years with {topic1.lower()}, here's what I learned.\",\n",
        "            \"\"  # Some videos have no description\n",
        "        ]\n",
        "        description = random.choice(descriptions)\n",
        "\n",
        "        data.append({\n",
        "            'video_id': f\"vid_{i:06d}\",\n",
        "            'trending_date': trending_date.strftime('%y.%d.%m'),\n",
        "            'title': title,\n",
        "            'channel_title': channel,\n",
        "            'category_id': category_id,\n",
        "            'views': views,\n",
        "            'likes': likes,\n",
        "            'dislikes': dislikes,\n",
        "            'comment_count': comment_count,\n",
        "            'description': description\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def contains_capitalized_word(title):\n",
        "    \"\"\"Check if title contains fully capitalized words (length > 1)\"\"\"\n",
        "    if pd.isna(title) or not isinstance(title, str):\n",
        "        return False\n",
        "\n",
        "    words = str(title).split()\n",
        "    for word in words:\n",
        "        if len(word) > 1 and word.isupper() and word.isalpha():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def analyze_youtube_data():\n",
        "    \"\"\"Complete YouTube trending videos analysis\"\"\"\n",
        "\n",
        "    print(\" Generating Clean YouTube Dataset...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Generate the dataset\n",
        "    df = generate_clean_youtube_dataset(2000)\n",
        "\n",
        "    print(f\" Generated {len(df)} videos across {df['channel_title'].nunique()} channels\")\n",
        "    print(f\" Dataset shape: {df.shape}\")\n",
        "    print(f\" Date range: {df['trending_date'].min()} to {df['trending_date'].max()}\")\n",
        "\n",
        "    # Add derived columns\n",
        "    df['title_length'] = df['title'].str.len()\n",
        "    df['contains_capitalized'] = df['title'].apply(contains_capitalized_word)\n",
        "    df['engagement_rate'] = (df['likes'] + df['comment_count']) / df['views']\n",
        "\n",
        "    # Basic statistics\n",
        "    print(f\"\\n Quick Stats:\")\n",
        "    print(f\"    Average views: {df['views'].mean():,.0f}\")\n",
        "    print(f\"    Median views: {df['views'].median():,.0f}\")\n",
        "    print(f\"    Average title length: {df['title_length'].mean():.1f} characters\")\n",
        "    print(f\"    Videos with CAPS: {df['contains_capitalized'].sum()} ({df['contains_capitalized'].mean()*100:.1f}%)\")\n",
        "\n",
        "    # Set up the plotting layout\n",
        "    fig = plt.figure(figsize=(20, 16))\n",
        "    fig.suptitle(' YouTube Trending Videos Analysis Dashboard', fontsize=20, fontweight='bold', y=0.98)\n",
        "\n",
        "    # 1. Pie Chart: Titles with Capitalized Words\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    caps_counts = df['contains_capitalized'].value_counts()\n",
        "    colors = ['#ff6b6b', '#4ecdc4']\n",
        "    labels = ['No Caps', 'Has CAPS']\n",
        "    wedges, texts, autotexts = ax1.pie(caps_counts.values, labels=labels, colors=colors,\n",
        "                                      autopct='%1.1f%%', startangle=45)\n",
        "    ax1.set_title('Titles with Capitalized Words', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # 2. Histogram: Title Length Distribution\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    sns.histplot(data=df, x='title_length', bins=25, kde=True, color='skyblue', alpha=0.7, ax=ax2)\n",
        "    ax2.axvline(df['title_length'].mean(), color='red', linestyle='--', alpha=0.8,\n",
        "                label=f'Mean: {df[\"title_length\"].mean():.0f}')\n",
        "    ax2.axvline(df['title_length'].median(), color='orange', linestyle='--', alpha=0.8,\n",
        "                label=f'Median: {df[\"title_length\"].median():.0f}')\n",
        "    ax2.set_xlabel('Title Length (characters)')\n",
        "    ax2.set_ylabel('Number of Videos')\n",
        "    ax2.set_title('Title Length Distribution', fontweight='bold')\n",
        "    ax2.legend()\n",
        "\n",
        "    # 3. Scatter: Views vs Title Length\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    sample_df = df.sample(n=min(500, len(df)), random_state=42)\n",
        "    colors_scatter = ['red' if x else 'blue' for x in sample_df['contains_capitalized']]\n",
        "    ax3.scatter(sample_df['views'], sample_df['title_length'], c=colors_scatter, alpha=0.6, s=30)\n",
        "\n",
        "    # Add trend line\n",
        "    z = np.polyfit(sample_df['views'], sample_df['title_length'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax3.plot(sample_df['views'], p(sample_df['views']), \"g--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "    ax3.set_xlabel('Views')\n",
        "    ax3.set_ylabel('Title Length')\n",
        "    ax3.set_title('Views vs Title Length', fontweight='bold')\n",
        "    ax3.ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
        "\n",
        "    # Create legend for colors\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=8, label='No Caps'),\n",
        "                      Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=8, label='Has Caps')]\n",
        "    ax3.legend(handles=legend_elements)\n",
        "\n",
        "    # 4. Top Channels by Average Views\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    channel_stats = df.groupby('channel_title').agg({\n",
        "        'views': ['mean', 'count'],\n",
        "        'likes': 'mean'\n",
        "    }).round(0)\n",
        "    channel_stats.columns = ['avg_views', 'video_count', 'avg_likes']\n",
        "    top_channels = channel_stats.nlargest(8, 'avg_views')\n",
        "\n",
        "    bars = ax4.barh(range(len(top_channels)), top_channels['avg_views'], color='lightcoral')\n",
        "    ax4.set_yticks(range(len(top_channels)))\n",
        "    ax4.set_yticklabels([name[:15] + '...' if len(name) > 15 else name for name in top_channels.index])\n",
        "    ax4.set_xlabel('Average Views')\n",
        "    ax4.set_title('Top Channels by Avg Views', fontweight='bold')\n",
        "    ax4.ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
        "\n",
        "    # 5. Views Distribution (Log Scale)\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    ax5.hist(np.log10(df['views']), bins=30, color='mediumseagreen', alpha=0.7, edgecolor='black')\n",
        "    ax5.set_xlabel('Log10(Views)')\n",
        "    ax5.set_ylabel('Frequency')\n",
        "    ax5.set_title('Views Distribution (Log Scale)', fontweight='bold')\n",
        "\n",
        "    # 6. Engagement Rate by Title Length\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    # Create bins for title length\n",
        "    df['length_bin'] = pd.cut(df['title_length'], bins=5, labels=['Very Short', 'Short', 'Medium', 'Long', 'Very Long'])\n",
        "    engagement_by_length = df.groupby('length_bin')['engagement_rate'].mean()\n",
        "\n",
        "    bars = ax6.bar(range(len(engagement_by_length)), engagement_by_length.values, color='gold', alpha=0.8)\n",
        "    ax6.set_xticks(range(len(engagement_by_length)))\n",
        "    ax6.set_xticklabels(engagement_by_length.index, rotation=45)\n",
        "    ax6.set_ylabel('Avg Engagement Rate')\n",
        "    ax6.set_title('Engagement by Title Length', fontweight='bold')\n",
        "\n",
        "    # 7. Most Common Words in Titles\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    # Extract words from titles\n",
        "    all_words = ' '.join(df['title']).lower()\n",
        "    # Remove common stop words and punctuation\n",
        "    import re\n",
        "    words = re.findall(r'\\b[a-z]{4,}\\b', all_words)  # Words 4+ characters\n",
        "    stop_words = {'that', 'this', 'with', 'from', 'they', 'have', 'will', 'your', 'about',\n",
        "                  'what', 'when', 'where', 'most', 'best', 'more', 'make', 'like', 'just', 'know'}\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    word_freq = Counter(filtered_words).most_common(12)\n",
        "    words, counts = zip(*word_freq)\n",
        "\n",
        "    bars = ax7.bar(range(len(words)), counts, color='plum')\n",
        "    ax7.set_xticks(range(len(words)))\n",
        "    ax7.set_xticklabels([w.capitalize() for w in words], rotation=45, ha='right')\n",
        "    ax7.set_ylabel('Frequency')\n",
        "    ax7.set_title('Most Common Words in Titles', fontweight='bold')\n",
        "\n",
        "    # 8. Correlation Heatmap\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    numeric_cols = ['views', 'likes', 'dislikes', 'comment_count', 'title_length', 'engagement_rate']\n",
        "    corr_matrix = df[numeric_cols].corr()\n",
        "\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "                square=True, ax=ax8, cbar_kws={\"shrink\": .8}, fmt='.2f')\n",
        "    ax8.set_title('Metrics Correlation Matrix', fontweight='bold')\n",
        "\n",
        "    # 9. Views by Category (Top categories)\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    category_views = df.groupby('category_id')['views'].mean().nlargest(8)\n",
        "\n",
        "    bars = ax9.bar(range(len(category_views)), category_views.values, color='lightblue')\n",
        "    ax9.set_xticks(range(len(category_views)))\n",
        "    ax9.set_xticklabels([f'Cat {cat}' for cat in category_views.index])\n",
        "    ax9.set_ylabel('Average Views')\n",
        "    ax9.set_title('Top Categories by Avg Views', fontweight='bold')\n",
        "    ax9.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.94)\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed insights\n",
        "    print(f\"\\n Detailed Analysis Results:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(f\" Title Analysis:\")\n",
        "    print(f\"    Average title length: {df['title_length'].mean():.1f}  {df['title_length'].std():.1f} chars\")\n",
        "    print(f\"    Titles with CAPS words: {df['contains_capitalized'].sum()} ({df['contains_capitalized'].mean()*100:.1f}%)\")\n",
        "    print(f\"    Longest title: {df['title_length'].max()} characters\")\n",
        "    print(f\"    Shortest title: {df['title_length'].min()} characters\")\n",
        "\n",
        "    print(f\"\\n Performance Metrics:\")\n",
        "    print(f\"    Total views across all videos: {df['views'].sum():,}\")\n",
        "    print(f\"    Average views: {df['views'].mean():,.0f}\")\n",
        "    print(f\"    Median views: {df['views'].median():,.0f}\")\n",
        "    print(f\"    Most viewed video: {df['views'].max():,} views\")\n",
        "    print(f\"    Average engagement rate: {df['engagement_rate'].mean():.4f}\")\n",
        "\n",
        "    print(f\"\\n Top Performing Content:\")\n",
        "    top_video = df.loc[df['views'].idxmax()]\n",
        "    print(f\"    Most viewed: '{top_video['title'][:60]}...'\")\n",
        "    print(f\"     Views: {top_video['views']:,}, Likes: {top_video['likes']:,}\")\n",
        "\n",
        "    print(f\"\\n Channel Insights:\")\n",
        "    print(f\"    Total unique channels: {df['channel_title'].nunique()}\")\n",
        "    print(f\"    Average videos per channel: {len(df) / df['channel_title'].nunique():.1f}\")\n",
        "\n",
        "    top_channel = channel_stats.index[0]\n",
        "    print(f\"    Top channel: {top_channel}\")\n",
        "    print(f\"     Average views: {channel_stats.loc[top_channel, 'avg_views']:,.0f}\")\n",
        "\n",
        "    # Show sample of the generated data\n",
        "    print(f\"\\n Sample Generated Data:\")\n",
        "    print(df[['title', 'channel_title', 'views', 'likes', 'title_length', 'contains_capitalized']].head(8).to_string(index=False))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Run the complete analysis\n",
        "if __name__ == \"__main__\":\n",
        "    df_analysis = analyze_youtube_data()\n",
        "\n",
        "    print(f\"\\n Analysis Complete!\")\n",
        "    print(f\"Generated clean dataset saved as 'df_analysis' with {len(df_analysis)} rows\")\n",
        "    print(f\"All visualizations displayed above show realistic YouTube trending video patterns\")\n"
      ],
      "metadata": {
        "id": "0q77xZG-GXuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "def generate_youtube_data(n_rows=1500):\n",
        "    \"\"\"Generate clean YouTube dataset\"\"\"\n",
        "\n",
        "    title_templates = [\n",
        "        \"HOW TO {} IN 2024 (WORKS!)\",\n",
        "        \"SHOCKING {} You Won't Believe\",\n",
        "        \"TOP 10 {} That Will BLOW Your Mind\",\n",
        "        \"Why {} Is Taking Over\",\n",
        "        \"Ultimate {} Guide for Beginners\",\n",
        "        \"24 HOURS of {} Challenge\",\n",
        "        \"INSANE {} Transformation\",\n",
        "        \"{} That Changed My Life\"\n",
        "    ]\n",
        "\n",
        "    topics = [\n",
        "        \"AI Technology\", \"Gaming\", \"Cooking\", \"Fitness\", \"Travel\",\n",
        "        \"Music Production\", \"Art Tutorial\", \"Business Tips\",\n",
        "        \"Photography\", \"Coding\", \"Life Hacks\", \"Investment\"\n",
        "    ]\n",
        "\n",
        "    channels = [\n",
        "        \"TechReview Central\", \"LifeHacker Pro\", \"Creative Studio\",\n",
        "        \"Fitness Guru\", \"Travel Adventures\", \"Gaming Zone\",\n",
        "        \"Business Insights\", \"Art Academy\", \"Code Academy\"\n",
        "    ]\n",
        "\n",
        "    data = []\n",
        "    for i in range(n_rows):\n",
        "        # Generate title\n",
        "        template = random.choice(title_templates)\n",
        "        topic = random.choice(topics)\n",
        "        title = template.format(topic)\n",
        "\n",
        "        # Add caps to some titles\n",
        "        if random.random() < 0.4:\n",
        "            words = title.split()\n",
        "            for j in range(min(2, len(words))):\n",
        "                idx = random.randint(0, len(words)-1)\n",
        "                if len(words[idx]) > 3:\n",
        "                    words[idx] = words[idx].upper()\n",
        "            title = \" \".join(words)\n",
        "\n",
        "        # Generate realistic metrics\n",
        "        views = max(1000, int(np.random.lognormal(11, 1.5)))\n",
        "        likes = max(1, int(views * (0.02 + random.random() * 0.05)))\n",
        "        comments = max(0, int(likes * random.uniform(0.1, 0.4)))\n",
        "\n",
        "        data.append({\n",
        "            'title': title,\n",
        "            'channel': random.choice(channels),\n",
        "            'views': views,\n",
        "            'likes': likes,\n",
        "            'comments': comments\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def contains_caps(title):\n",
        "    \"\"\"Check if title has capitalized words\"\"\"\n",
        "    words = str(title).split()\n",
        "    return any(len(word) > 1 and word.isupper() for word in words)\n",
        "\n",
        "def analyze_youtube():\n",
        "    \"\"\"Main analysis function\"\"\"\n",
        "\n",
        "    print(\" Generating YouTube Dataset...\")\n",
        "    df = generate_youtube_data(1500)\n",
        "\n",
        "    # Add analysis columns\n",
        "    df['title_length'] = df['title'].str.len()\n",
        "    df['has_caps'] = df['title'].apply(contains_caps)\n",
        "    df['engagement'] = (df['likes'] + df['comments']) / df['views']\n",
        "\n",
        "    print(f\" Generated {len(df)} videos from {df['channel'].nunique()} channels\")\n",
        "    print(f\" Average views: {df['views'].mean():,.0f}\")\n",
        "    print(f\" Average title length: {df['title_length'].mean():.1f} chars\")\n",
        "    print(f\" Videos with CAPS: {df['has_caps'].mean()*100:.1f}%\")\n",
        "\n",
        "    # Create visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(' YouTube Analysis Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Capitalization Pie Chart\n",
        "    caps_data = df['has_caps'].value_counts()\n",
        "    axes[0,0].pie(caps_data.values, labels=['No Caps', 'Has CAPS'],\n",
        "                  colors=['#ff6b6b', '#4ecdc4'], autopct='%1.1f%%', startangle=45)\n",
        "    axes[0,0].set_title('Titles with Capitalized Words', fontweight='bold')\n",
        "\n",
        "    # 2. Views vs Title Length Scatter\n",
        "    sample = df.sample(300, random_state=42)\n",
        "    colors = ['red' if x else 'blue' for x in sample['has_caps']]\n",
        "    axes[0,1].scatter(sample['views'], sample['title_length'], c=colors, alpha=0.6, s=20)\n",
        "    axes[0,1].set_xlabel('Views')\n",
        "    axes[0,1].set_ylabel('Title Length')\n",
        "    axes[0,1].set_title('Views vs Title Length', fontweight='bold')\n",
        "    axes[0,1].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
        "\n",
        "    # 3. Top Channels\n",
        "    channel_avg = df.groupby('channel')['views'].mean().nlargest(6)\n",
        "    axes[1,0].barh(range(len(channel_avg)), channel_avg.values, color='lightcoral')\n",
        "    axes[1,0].set_yticks(range(len(channel_avg)))\n",
        "    axes[1,0].set_yticklabels([name[:12] + '...' if len(name) > 12 else name\n",
        "                               for name in channel_avg.index])\n",
        "    axes[1,0].set_xlabel('Average Views')\n",
        "    axes[1,0].set_title('Top Channels', fontweight='bold')\n",
        "    axes[1,0].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
        "\n",
        "    # 4. Word Frequency\n",
        "    all_words = ' '.join(df['title']).lower()\n",
        "    import re\n",
        "    words = re.findall(r'\\b[a-z]{4,}\\b', all_words)\n",
        "    stop_words = {'that', 'this', 'with', 'your', 'will', 'make', 'best'}\n",
        "    filtered = [w for w in words if w not in stop_words]\n",
        "\n",
        "    word_freq = Counter(filtered).most_common(10)\n",
        "    words, counts = zip(*word_freq)\n",
        "\n",
        "    axes[1,1].bar(range(len(words)), counts, color='plum')\n",
        "    axes[1,1].set_xticks(range(len(words)))\n",
        "    axes[1,1].set_xticklabels([w.capitalize() for w in words], rotation=45, ha='right')\n",
        "    axes[1,1].set_ylabel('Frequency')\n",
        "    axes[1,1].set_title('Common Words in Titles', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Summary insights\n",
        "    print(f\"\\n Key Insights:\")\n",
        "    print(f\"    Most viewed video: {df['views'].max():,} views\")\n",
        "    print(f\"    Top channel: {channel_avg.index[0]} (avg: {channel_avg.iloc[0]:,.0f} views)\")\n",
        "    print(f\"    Engagement rate: {df['engagement'].mean():.4f}\")\n",
        "\n",
        "    # Sample data\n",
        "    print(f\"\\n Sample Data:\")\n",
        "    sample_cols = ['title', 'channel', 'views', 'likes', 'has_caps']\n",
        "    print(df[sample_cols].head(5).to_string(index=False))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Run analysis\n",
        "if __name__ == \"__main__\":\n",
        "    df_result = analyze_youtube()\n",
        "    print(f\"\\n Analysis complete! Dataset ready for further exploration.\")"
      ],
      "metadata": {
        "id": "um6-cC2JIzjg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}